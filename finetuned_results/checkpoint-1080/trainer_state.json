{
  "best_global_step": 1080,
  "best_metric": 0.014543057419359684,
  "best_model_checkpoint": "./finetuned_results/checkpoint-1080",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1080,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01855717930874507,
      "grad_norm": 38.8089599609375,
      "learning_rate": 0.0,
      "loss": 9.8354,
      "step": 5
    },
    {
      "epoch": 0.03711435861749014,
      "grad_norm": NaN,
      "learning_rate": 2e-05,
      "loss": 9.4368,
      "step": 10
    },
    {
      "epoch": 0.055671537926235214,
      "grad_norm": 33.21611022949219,
      "learning_rate": 3.6e-05,
      "loss": 8.3747,
      "step": 15
    },
    {
      "epoch": 0.07422871723498028,
      "grad_norm": 37.239139556884766,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 4.7388,
      "step": 20
    },
    {
      "epoch": 0.09278589654372535,
      "grad_norm": 1.2410410642623901,
      "learning_rate": 7.6e-05,
      "loss": 0.4858,
      "step": 25
    },
    {
      "epoch": 0.11134307585247043,
      "grad_norm": 0.7036065459251404,
      "learning_rate": 9.6e-05,
      "loss": 0.1087,
      "step": 30
    },
    {
      "epoch": 0.1299002551612155,
      "grad_norm": 0.3889577388763428,
      "learning_rate": 0.000116,
      "loss": 0.0763,
      "step": 35
    },
    {
      "epoch": 0.14845743446996057,
      "grad_norm": 0.2761220932006836,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.0532,
      "step": 40
    },
    {
      "epoch": 0.16701461377870563,
      "grad_norm": 0.3038530945777893,
      "learning_rate": 0.00015600000000000002,
      "loss": 0.0527,
      "step": 45
    },
    {
      "epoch": 0.1855717930874507,
      "grad_norm": 0.2659846842288971,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.0563,
      "step": 50
    },
    {
      "epoch": 0.2041289723961958,
      "grad_norm": 0.2929856479167938,
      "learning_rate": 0.000196,
      "loss": 0.0395,
      "step": 55
    },
    {
      "epoch": 0.22268615170494085,
      "grad_norm": 0.2642553448677063,
      "learning_rate": 0.0001993846153846154,
      "loss": 0.0441,
      "step": 60
    },
    {
      "epoch": 0.24124333101368592,
      "grad_norm": 0.21965458989143372,
      "learning_rate": 0.00019861538461538462,
      "loss": 0.038,
      "step": 65
    },
    {
      "epoch": 0.259800510322431,
      "grad_norm": 0.2293543964624405,
      "learning_rate": 0.00019784615384615386,
      "loss": 0.0379,
      "step": 70
    },
    {
      "epoch": 0.2783576896311761,
      "grad_norm": 0.2037859708070755,
      "learning_rate": 0.00019707692307692308,
      "loss": 0.0303,
      "step": 75
    },
    {
      "epoch": 0.29691486893992114,
      "grad_norm": 0.23827320337295532,
      "learning_rate": 0.00019630769230769232,
      "loss": 0.0404,
      "step": 80
    },
    {
      "epoch": 0.3154720482486662,
      "grad_norm": 0.17879173159599304,
      "learning_rate": 0.00019553846153846154,
      "loss": 0.0332,
      "step": 85
    },
    {
      "epoch": 0.33402922755741127,
      "grad_norm": 0.15372444689273834,
      "learning_rate": 0.00019476923076923078,
      "loss": 0.0346,
      "step": 90
    },
    {
      "epoch": 0.35258640686615633,
      "grad_norm": 0.1595124453306198,
      "learning_rate": 0.000194,
      "loss": 0.0272,
      "step": 95
    },
    {
      "epoch": 0.3711435861749014,
      "grad_norm": 0.17631758749485016,
      "learning_rate": 0.00019323076923076924,
      "loss": 0.0274,
      "step": 100
    },
    {
      "epoch": 0.38970076548364646,
      "grad_norm": 0.1983204185962677,
      "learning_rate": 0.00019246153846153846,
      "loss": 0.0306,
      "step": 105
    },
    {
      "epoch": 0.4082579447923916,
      "grad_norm": 0.2341485321521759,
      "learning_rate": 0.0001916923076923077,
      "loss": 0.0309,
      "step": 110
    },
    {
      "epoch": 0.42681512410113664,
      "grad_norm": 0.2646656930446625,
      "learning_rate": 0.00019092307692307695,
      "loss": 0.0314,
      "step": 115
    },
    {
      "epoch": 0.4453723034098817,
      "grad_norm": 0.1300765722990036,
      "learning_rate": 0.00019015384615384616,
      "loss": 0.0284,
      "step": 120
    },
    {
      "epoch": 0.4639294827186268,
      "grad_norm": 0.17579887807369232,
      "learning_rate": 0.0001893846153846154,
      "loss": 0.0308,
      "step": 125
    },
    {
      "epoch": 0.48248666202737184,
      "grad_norm": 0.1443580538034439,
      "learning_rate": 0.00018861538461538462,
      "loss": 0.0264,
      "step": 130
    },
    {
      "epoch": 0.5010438413361169,
      "grad_norm": 0.12289287149906158,
      "learning_rate": 0.00018784615384615384,
      "loss": 0.0321,
      "step": 135
    },
    {
      "epoch": 0.519601020644862,
      "grad_norm": 0.1827811300754547,
      "learning_rate": 0.00018707692307692308,
      "loss": 0.0261,
      "step": 140
    },
    {
      "epoch": 0.538158199953607,
      "grad_norm": 0.15670245885849,
      "learning_rate": 0.00018630769230769232,
      "loss": 0.0291,
      "step": 145
    },
    {
      "epoch": 0.5567153792623522,
      "grad_norm": 0.13466352224349976,
      "learning_rate": 0.00018553846153846154,
      "loss": 0.026,
      "step": 150
    },
    {
      "epoch": 0.5752725585710972,
      "grad_norm": 0.18617753684520721,
      "learning_rate": 0.00018476923076923078,
      "loss": 0.0304,
      "step": 155
    },
    {
      "epoch": 0.5938297378798423,
      "grad_norm": 0.1621847003698349,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.0295,
      "step": 160
    },
    {
      "epoch": 0.6123869171885873,
      "grad_norm": 0.12930400669574738,
      "learning_rate": 0.00018323076923076924,
      "loss": 0.0216,
      "step": 165
    },
    {
      "epoch": 0.6309440964973324,
      "grad_norm": 0.16892869770526886,
      "learning_rate": 0.00018246153846153846,
      "loss": 0.0268,
      "step": 170
    },
    {
      "epoch": 0.6495012758060775,
      "grad_norm": 0.18763767182826996,
      "learning_rate": 0.0001816923076923077,
      "loss": 0.0301,
      "step": 175
    },
    {
      "epoch": 0.6680584551148225,
      "grad_norm": 0.18306219577789307,
      "learning_rate": 0.00018092307692307692,
      "loss": 0.0284,
      "step": 180
    },
    {
      "epoch": 0.6866156344235677,
      "grad_norm": 0.1548192799091339,
      "learning_rate": 0.00018015384615384616,
      "loss": 0.027,
      "step": 185
    },
    {
      "epoch": 0.7051728137323127,
      "grad_norm": 0.23606309294700623,
      "learning_rate": 0.0001793846153846154,
      "loss": 0.0311,
      "step": 190
    },
    {
      "epoch": 0.7237299930410578,
      "grad_norm": 0.15790016949176788,
      "learning_rate": 0.00017861538461538462,
      "loss": 0.0216,
      "step": 195
    },
    {
      "epoch": 0.7422871723498028,
      "grad_norm": 0.2178088128566742,
      "learning_rate": 0.00017784615384615387,
      "loss": 0.0228,
      "step": 200
    },
    {
      "epoch": 0.7608443516585479,
      "grad_norm": 0.24372854828834534,
      "learning_rate": 0.0001770769230769231,
      "loss": 0.0273,
      "step": 205
    },
    {
      "epoch": 0.7794015309672929,
      "grad_norm": 0.1263342797756195,
      "learning_rate": 0.0001763076923076923,
      "loss": 0.0262,
      "step": 210
    },
    {
      "epoch": 0.797958710276038,
      "grad_norm": 0.12960711121559143,
      "learning_rate": 0.00017553846153846154,
      "loss": 0.0286,
      "step": 215
    },
    {
      "epoch": 0.8165158895847832,
      "grad_norm": 0.15585315227508545,
      "learning_rate": 0.00017476923076923078,
      "loss": 0.0271,
      "step": 220
    },
    {
      "epoch": 0.8350730688935282,
      "grad_norm": 0.16863706707954407,
      "learning_rate": 0.000174,
      "loss": 0.0217,
      "step": 225
    },
    {
      "epoch": 0.8536302482022733,
      "grad_norm": 0.16825538873672485,
      "learning_rate": 0.00017323076923076924,
      "loss": 0.0242,
      "step": 230
    },
    {
      "epoch": 0.8721874275110183,
      "grad_norm": 0.13210777938365936,
      "learning_rate": 0.0001724615384615385,
      "loss": 0.0285,
      "step": 235
    },
    {
      "epoch": 0.8907446068197634,
      "grad_norm": 0.1504346877336502,
      "learning_rate": 0.0001716923076923077,
      "loss": 0.0185,
      "step": 240
    },
    {
      "epoch": 0.9093017861285084,
      "grad_norm": 0.15383395552635193,
      "learning_rate": 0.00017092307692307695,
      "loss": 0.0258,
      "step": 245
    },
    {
      "epoch": 0.9278589654372535,
      "grad_norm": 0.10885468125343323,
      "learning_rate": 0.00017015384615384616,
      "loss": 0.0251,
      "step": 250
    },
    {
      "epoch": 0.9464161447459986,
      "grad_norm": 0.15276454389095306,
      "learning_rate": 0.00016938461538461538,
      "loss": 0.0235,
      "step": 255
    },
    {
      "epoch": 0.9649733240547437,
      "grad_norm": 0.10510169714689255,
      "learning_rate": 0.00016861538461538462,
      "loss": 0.018,
      "step": 260
    },
    {
      "epoch": 0.9835305033634888,
      "grad_norm": 0.16921551525592804,
      "learning_rate": 0.00016784615384615387,
      "loss": 0.0228,
      "step": 265
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.18809951841831207,
      "learning_rate": 0.00016707692307692308,
      "loss": 0.0243,
      "step": 270
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.021238837391138077,
      "eval_runtime": 16.3887,
      "eval_samples_per_second": 29.228,
      "eval_steps_per_second": 7.322,
      "step": 270
    },
    {
      "epoch": 1.0185571793087451,
      "grad_norm": 0.15007486939430237,
      "learning_rate": 0.00016630769230769233,
      "loss": 0.0187,
      "step": 275
    },
    {
      "epoch": 1.0371143586174902,
      "grad_norm": 0.16913393139839172,
      "learning_rate": 0.00016553846153846154,
      "loss": 0.0203,
      "step": 280
    },
    {
      "epoch": 1.0556715379262351,
      "grad_norm": 0.10675504803657532,
      "learning_rate": 0.00016476923076923079,
      "loss": 0.016,
      "step": 285
    },
    {
      "epoch": 1.0742287172349803,
      "grad_norm": 0.18050570785999298,
      "learning_rate": 0.000164,
      "loss": 0.0179,
      "step": 290
    },
    {
      "epoch": 1.0927858965437254,
      "grad_norm": 0.1730862706899643,
      "learning_rate": 0.00016323076923076922,
      "loss": 0.0205,
      "step": 295
    },
    {
      "epoch": 1.1113430758524705,
      "grad_norm": 0.14059318602085114,
      "learning_rate": 0.00016246153846153846,
      "loss": 0.0164,
      "step": 300
    },
    {
      "epoch": 1.1299002551612154,
      "grad_norm": 0.14744064211845398,
      "learning_rate": 0.0001616923076923077,
      "loss": 0.0208,
      "step": 305
    },
    {
      "epoch": 1.1484574344699605,
      "grad_norm": 0.1750488430261612,
      "learning_rate": 0.00016092307692307692,
      "loss": 0.0169,
      "step": 310
    },
    {
      "epoch": 1.1670146137787056,
      "grad_norm": 0.15975648164749146,
      "learning_rate": 0.00016015384615384616,
      "loss": 0.0175,
      "step": 315
    },
    {
      "epoch": 1.1855717930874508,
      "grad_norm": 0.13709257543087006,
      "learning_rate": 0.0001593846153846154,
      "loss": 0.0181,
      "step": 320
    },
    {
      "epoch": 1.2041289723961959,
      "grad_norm": 0.13102348148822784,
      "learning_rate": 0.00015861538461538462,
      "loss": 0.0213,
      "step": 325
    },
    {
      "epoch": 1.2226861517049408,
      "grad_norm": 0.13878598809242249,
      "learning_rate": 0.00015784615384615384,
      "loss": 0.0165,
      "step": 330
    },
    {
      "epoch": 1.241243331013686,
      "grad_norm": 0.15473870933055878,
      "learning_rate": 0.00015707692307692308,
      "loss": 0.0239,
      "step": 335
    },
    {
      "epoch": 1.259800510322431,
      "grad_norm": 0.1348075419664383,
      "learning_rate": 0.0001563076923076923,
      "loss": 0.0155,
      "step": 340
    },
    {
      "epoch": 1.2783576896311761,
      "grad_norm": 0.16818682849407196,
      "learning_rate": 0.00015553846153846154,
      "loss": 0.0197,
      "step": 345
    },
    {
      "epoch": 1.296914868939921,
      "grad_norm": 0.10446669161319733,
      "learning_rate": 0.0001547692307692308,
      "loss": 0.0148,
      "step": 350
    },
    {
      "epoch": 1.3154720482486661,
      "grad_norm": 0.16895678639411926,
      "learning_rate": 0.000154,
      "loss": 0.022,
      "step": 355
    },
    {
      "epoch": 1.3340292275574113,
      "grad_norm": 0.19180884957313538,
      "learning_rate": 0.00015323076923076925,
      "loss": 0.018,
      "step": 360
    },
    {
      "epoch": 1.3525864068661564,
      "grad_norm": 0.06493104994297028,
      "learning_rate": 0.0001524615384615385,
      "loss": 0.0144,
      "step": 365
    },
    {
      "epoch": 1.3711435861749015,
      "grad_norm": 0.15282370150089264,
      "learning_rate": 0.00015169230769230768,
      "loss": 0.0172,
      "step": 370
    },
    {
      "epoch": 1.3897007654836464,
      "grad_norm": 0.19011466205120087,
      "learning_rate": 0.00015092307692307692,
      "loss": 0.0168,
      "step": 375
    },
    {
      "epoch": 1.4082579447923915,
      "grad_norm": 0.15913726389408112,
      "learning_rate": 0.00015015384615384617,
      "loss": 0.0192,
      "step": 380
    },
    {
      "epoch": 1.4268151241011366,
      "grad_norm": 0.15188664197921753,
      "learning_rate": 0.00014938461538461538,
      "loss": 0.018,
      "step": 385
    },
    {
      "epoch": 1.4453723034098818,
      "grad_norm": 0.13503815233707428,
      "learning_rate": 0.00014861538461538462,
      "loss": 0.0189,
      "step": 390
    },
    {
      "epoch": 1.4639294827186267,
      "grad_norm": 0.14167001843452454,
      "learning_rate": 0.00014784615384615387,
      "loss": 0.0164,
      "step": 395
    },
    {
      "epoch": 1.4824866620273718,
      "grad_norm": 0.10476996004581451,
      "learning_rate": 0.00014707692307692308,
      "loss": 0.0144,
      "step": 400
    },
    {
      "epoch": 1.501043841336117,
      "grad_norm": 0.15170934796333313,
      "learning_rate": 0.00014630769230769233,
      "loss": 0.02,
      "step": 405
    },
    {
      "epoch": 1.519601020644862,
      "grad_norm": 0.16412486135959625,
      "learning_rate": 0.00014553846153846154,
      "loss": 0.0216,
      "step": 410
    },
    {
      "epoch": 1.5381581999536071,
      "grad_norm": 0.13982005417346954,
      "learning_rate": 0.00014476923076923076,
      "loss": 0.014,
      "step": 415
    },
    {
      "epoch": 1.5567153792623523,
      "grad_norm": 0.1864977329969406,
      "learning_rate": 0.000144,
      "loss": 0.0174,
      "step": 420
    },
    {
      "epoch": 1.5752725585710972,
      "grad_norm": 0.12625057995319366,
      "learning_rate": 0.00014323076923076925,
      "loss": 0.0178,
      "step": 425
    },
    {
      "epoch": 1.5938297378798423,
      "grad_norm": 0.11064094305038452,
      "learning_rate": 0.00014246153846153846,
      "loss": 0.0156,
      "step": 430
    },
    {
      "epoch": 1.6123869171885872,
      "grad_norm": 0.15597233176231384,
      "learning_rate": 0.0001416923076923077,
      "loss": 0.0174,
      "step": 435
    },
    {
      "epoch": 1.6309440964973323,
      "grad_norm": 0.18703259527683258,
      "learning_rate": 0.00014092307692307692,
      "loss": 0.0159,
      "step": 440
    },
    {
      "epoch": 1.6495012758060774,
      "grad_norm": 0.16807477176189423,
      "learning_rate": 0.00014015384615384617,
      "loss": 0.018,
      "step": 445
    },
    {
      "epoch": 1.6680584551148225,
      "grad_norm": 0.10381780564785004,
      "learning_rate": 0.0001393846153846154,
      "loss": 0.0139,
      "step": 450
    },
    {
      "epoch": 1.6866156344235677,
      "grad_norm": 0.10189380496740341,
      "learning_rate": 0.00013861538461538463,
      "loss": 0.0119,
      "step": 455
    },
    {
      "epoch": 1.7051728137323128,
      "grad_norm": 0.12114620208740234,
      "learning_rate": 0.00013784615384615384,
      "loss": 0.0149,
      "step": 460
    },
    {
      "epoch": 1.723729993041058,
      "grad_norm": 0.10078287869691849,
      "learning_rate": 0.00013707692307692309,
      "loss": 0.0131,
      "step": 465
    },
    {
      "epoch": 1.7422871723498028,
      "grad_norm": 0.24269691109657288,
      "learning_rate": 0.0001363076923076923,
      "loss": 0.0231,
      "step": 470
    },
    {
      "epoch": 1.760844351658548,
      "grad_norm": 0.1765856295824051,
      "learning_rate": 0.00013553846153846154,
      "loss": 0.0166,
      "step": 475
    },
    {
      "epoch": 1.7794015309672928,
      "grad_norm": 0.17156951129436493,
      "learning_rate": 0.0001347692307692308,
      "loss": 0.0209,
      "step": 480
    },
    {
      "epoch": 1.797958710276038,
      "grad_norm": 0.11883572489023209,
      "learning_rate": 0.000134,
      "loss": 0.014,
      "step": 485
    },
    {
      "epoch": 1.816515889584783,
      "grad_norm": 0.11890970915555954,
      "learning_rate": 0.00013323076923076925,
      "loss": 0.0136,
      "step": 490
    },
    {
      "epoch": 1.8350730688935282,
      "grad_norm": 0.20929576456546783,
      "learning_rate": 0.00013246153846153846,
      "loss": 0.0144,
      "step": 495
    },
    {
      "epoch": 1.8536302482022733,
      "grad_norm": 0.1162775382399559,
      "learning_rate": 0.00013169230769230768,
      "loss": 0.0206,
      "step": 500
    },
    {
      "epoch": 1.8721874275110184,
      "grad_norm": 0.17226330935955048,
      "learning_rate": 0.00013092307692307692,
      "loss": 0.0176,
      "step": 505
    },
    {
      "epoch": 1.8907446068197635,
      "grad_norm": 0.17253130674362183,
      "learning_rate": 0.00013015384615384617,
      "loss": 0.0185,
      "step": 510
    },
    {
      "epoch": 1.9093017861285084,
      "grad_norm": 0.119057796895504,
      "learning_rate": 0.00012938461538461538,
      "loss": 0.0163,
      "step": 515
    },
    {
      "epoch": 1.9278589654372535,
      "grad_norm": 0.17467600107192993,
      "learning_rate": 0.00012861538461538463,
      "loss": 0.0167,
      "step": 520
    },
    {
      "epoch": 1.9464161447459984,
      "grad_norm": 0.08070947229862213,
      "learning_rate": 0.00012784615384615387,
      "loss": 0.0113,
      "step": 525
    },
    {
      "epoch": 1.9649733240547436,
      "grad_norm": 0.12217482924461365,
      "learning_rate": 0.00012707692307692309,
      "loss": 0.0122,
      "step": 530
    },
    {
      "epoch": 1.9835305033634887,
      "grad_norm": 0.1414831280708313,
      "learning_rate": 0.0001263076923076923,
      "loss": 0.0203,
      "step": 535
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.22517547011375427,
      "learning_rate": 0.00012553846153846155,
      "loss": 0.0147,
      "step": 540
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.016786277294158936,
      "eval_runtime": 16.3896,
      "eval_samples_per_second": 29.226,
      "eval_steps_per_second": 7.322,
      "step": 540
    },
    {
      "epoch": 2.018557179308745,
      "grad_norm": 0.059819385409355164,
      "learning_rate": 0.00012476923076923076,
      "loss": 0.0082,
      "step": 545
    },
    {
      "epoch": 2.0371143586174902,
      "grad_norm": 0.1256519854068756,
      "learning_rate": 0.000124,
      "loss": 0.0083,
      "step": 550
    },
    {
      "epoch": 2.0556715379262354,
      "grad_norm": 0.09597063809633255,
      "learning_rate": 0.00012323076923076925,
      "loss": 0.0122,
      "step": 555
    },
    {
      "epoch": 2.0742287172349805,
      "grad_norm": 0.1471552699804306,
      "learning_rate": 0.00012246153846153846,
      "loss": 0.0121,
      "step": 560
    },
    {
      "epoch": 2.092785896543725,
      "grad_norm": 0.16253943741321564,
      "learning_rate": 0.00012169230769230771,
      "loss": 0.0115,
      "step": 565
    },
    {
      "epoch": 2.1113430758524703,
      "grad_norm": 0.13895413279533386,
      "learning_rate": 0.00012092307692307694,
      "loss": 0.0128,
      "step": 570
    },
    {
      "epoch": 2.1299002551612154,
      "grad_norm": 0.10360680520534515,
      "learning_rate": 0.00012015384615384615,
      "loss": 0.0116,
      "step": 575
    },
    {
      "epoch": 2.1484574344699605,
      "grad_norm": 0.13021087646484375,
      "learning_rate": 0.00011938461538461538,
      "loss": 0.0106,
      "step": 580
    },
    {
      "epoch": 2.1670146137787056,
      "grad_norm": 0.22056837379932404,
      "learning_rate": 0.00011861538461538461,
      "loss": 0.0098,
      "step": 585
    },
    {
      "epoch": 2.1855717930874508,
      "grad_norm": 0.13625146448612213,
      "learning_rate": 0.00011784615384615386,
      "loss": 0.0097,
      "step": 590
    },
    {
      "epoch": 2.204128972396196,
      "grad_norm": 0.2134900689125061,
      "learning_rate": 0.00011707692307692309,
      "loss": 0.009,
      "step": 595
    },
    {
      "epoch": 2.222686151704941,
      "grad_norm": 0.2082429975271225,
      "learning_rate": 0.00011630769230769232,
      "loss": 0.0116,
      "step": 600
    },
    {
      "epoch": 2.241243331013686,
      "grad_norm": 0.13143406808376312,
      "learning_rate": 0.00011553846153846155,
      "loss": 0.0087,
      "step": 605
    },
    {
      "epoch": 2.259800510322431,
      "grad_norm": 0.14559264481067657,
      "learning_rate": 0.00011476923076923079,
      "loss": 0.0111,
      "step": 610
    },
    {
      "epoch": 2.278357689631176,
      "grad_norm": 0.12656192481517792,
      "learning_rate": 0.00011399999999999999,
      "loss": 0.0115,
      "step": 615
    },
    {
      "epoch": 2.296914868939921,
      "grad_norm": 0.1258399337530136,
      "learning_rate": 0.00011323076923076922,
      "loss": 0.0085,
      "step": 620
    },
    {
      "epoch": 2.315472048248666,
      "grad_norm": 0.18504324555397034,
      "learning_rate": 0.00011246153846153847,
      "loss": 0.0144,
      "step": 625
    },
    {
      "epoch": 2.3340292275574113,
      "grad_norm": 0.13832895457744598,
      "learning_rate": 0.0001116923076923077,
      "loss": 0.0087,
      "step": 630
    },
    {
      "epoch": 2.3525864068661564,
      "grad_norm": 0.17226488888263702,
      "learning_rate": 0.00011092307692307693,
      "loss": 0.0129,
      "step": 635
    },
    {
      "epoch": 2.3711435861749015,
      "grad_norm": 0.22714519500732422,
      "learning_rate": 0.00011015384615384617,
      "loss": 0.0098,
      "step": 640
    },
    {
      "epoch": 2.3897007654836466,
      "grad_norm": 0.09366607666015625,
      "learning_rate": 0.0001093846153846154,
      "loss": 0.0085,
      "step": 645
    },
    {
      "epoch": 2.4082579447923917,
      "grad_norm": 0.17913204431533813,
      "learning_rate": 0.00010861538461538463,
      "loss": 0.0129,
      "step": 650
    },
    {
      "epoch": 2.426815124101137,
      "grad_norm": 0.14672045409679413,
      "learning_rate": 0.00010784615384615384,
      "loss": 0.0108,
      "step": 655
    },
    {
      "epoch": 2.4453723034098815,
      "grad_norm": 0.1498175710439682,
      "learning_rate": 0.00010707692307692307,
      "loss": 0.0108,
      "step": 660
    },
    {
      "epoch": 2.4639294827186267,
      "grad_norm": 0.11811774224042892,
      "learning_rate": 0.0001063076923076923,
      "loss": 0.0105,
      "step": 665
    },
    {
      "epoch": 2.482486662027372,
      "grad_norm": 0.1172291710972786,
      "learning_rate": 0.00010553846153846155,
      "loss": 0.0118,
      "step": 670
    },
    {
      "epoch": 2.501043841336117,
      "grad_norm": 0.16379137337207794,
      "learning_rate": 0.00010476923076923078,
      "loss": 0.0131,
      "step": 675
    },
    {
      "epoch": 2.519601020644862,
      "grad_norm": 0.10665182024240494,
      "learning_rate": 0.00010400000000000001,
      "loss": 0.0095,
      "step": 680
    },
    {
      "epoch": 2.538158199953607,
      "grad_norm": 0.09470811486244202,
      "learning_rate": 0.00010323076923076924,
      "loss": 0.0058,
      "step": 685
    },
    {
      "epoch": 2.5567153792623523,
      "grad_norm": 0.20821316540241241,
      "learning_rate": 0.00010246153846153848,
      "loss": 0.011,
      "step": 690
    },
    {
      "epoch": 2.575272558571097,
      "grad_norm": 0.14301271736621857,
      "learning_rate": 0.00010169230769230768,
      "loss": 0.0093,
      "step": 695
    },
    {
      "epoch": 2.593829737879842,
      "grad_norm": 0.15309156477451324,
      "learning_rate": 0.00010092307692307693,
      "loss": 0.008,
      "step": 700
    },
    {
      "epoch": 2.612386917188587,
      "grad_norm": 0.1964796483516693,
      "learning_rate": 0.00010015384615384616,
      "loss": 0.0084,
      "step": 705
    },
    {
      "epoch": 2.6309440964973323,
      "grad_norm": 0.11998242884874344,
      "learning_rate": 9.938461538461539e-05,
      "loss": 0.0117,
      "step": 710
    },
    {
      "epoch": 2.6495012758060774,
      "grad_norm": 0.15159264206886292,
      "learning_rate": 9.861538461538462e-05,
      "loss": 0.0093,
      "step": 715
    },
    {
      "epoch": 2.6680584551148225,
      "grad_norm": 0.17521707713603973,
      "learning_rate": 9.784615384615386e-05,
      "loss": 0.007,
      "step": 720
    },
    {
      "epoch": 2.6866156344235677,
      "grad_norm": 0.1031571701169014,
      "learning_rate": 9.707692307692308e-05,
      "loss": 0.0084,
      "step": 725
    },
    {
      "epoch": 2.7051728137323128,
      "grad_norm": 0.15733803808689117,
      "learning_rate": 9.63076923076923e-05,
      "loss": 0.014,
      "step": 730
    },
    {
      "epoch": 2.723729993041058,
      "grad_norm": 0.10416138172149658,
      "learning_rate": 9.553846153846155e-05,
      "loss": 0.0094,
      "step": 735
    },
    {
      "epoch": 2.742287172349803,
      "grad_norm": 0.15293897688388824,
      "learning_rate": 9.476923076923078e-05,
      "loss": 0.0103,
      "step": 740
    },
    {
      "epoch": 2.760844351658548,
      "grad_norm": 0.09403581917285919,
      "learning_rate": 9.4e-05,
      "loss": 0.0104,
      "step": 745
    },
    {
      "epoch": 2.779401530967293,
      "grad_norm": 0.09773252159357071,
      "learning_rate": 9.323076923076924e-05,
      "loss": 0.0085,
      "step": 750
    },
    {
      "epoch": 2.797958710276038,
      "grad_norm": 0.2174227088689804,
      "learning_rate": 9.246153846153847e-05,
      "loss": 0.0097,
      "step": 755
    },
    {
      "epoch": 2.816515889584783,
      "grad_norm": 0.11812641471624374,
      "learning_rate": 9.16923076923077e-05,
      "loss": 0.008,
      "step": 760
    },
    {
      "epoch": 2.835073068893528,
      "grad_norm": 0.2244531810283661,
      "learning_rate": 9.092307692307693e-05,
      "loss": 0.0106,
      "step": 765
    },
    {
      "epoch": 2.8536302482022733,
      "grad_norm": 0.18592719733715057,
      "learning_rate": 9.015384615384616e-05,
      "loss": 0.0109,
      "step": 770
    },
    {
      "epoch": 2.8721874275110184,
      "grad_norm": 0.15249167382717133,
      "learning_rate": 8.938461538461539e-05,
      "loss": 0.0085,
      "step": 775
    },
    {
      "epoch": 2.8907446068197635,
      "grad_norm": 0.19976983964443207,
      "learning_rate": 8.861538461538462e-05,
      "loss": 0.0114,
      "step": 780
    },
    {
      "epoch": 2.909301786128508,
      "grad_norm": 0.1558162420988083,
      "learning_rate": 8.784615384615386e-05,
      "loss": 0.0136,
      "step": 785
    },
    {
      "epoch": 2.9278589654372533,
      "grad_norm": 0.1225898414850235,
      "learning_rate": 8.707692307692308e-05,
      "loss": 0.0079,
      "step": 790
    },
    {
      "epoch": 2.9464161447459984,
      "grad_norm": 0.17257529497146606,
      "learning_rate": 8.63076923076923e-05,
      "loss": 0.0091,
      "step": 795
    },
    {
      "epoch": 2.9649733240547436,
      "grad_norm": 0.10453879833221436,
      "learning_rate": 8.553846153846155e-05,
      "loss": 0.0103,
      "step": 800
    },
    {
      "epoch": 2.9835305033634887,
      "grad_norm": 0.18440969288349152,
      "learning_rate": 8.476923076923078e-05,
      "loss": 0.0143,
      "step": 805
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.23095448315143585,
      "learning_rate": 8.4e-05,
      "loss": 0.0095,
      "step": 810
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.014892174862325191,
      "eval_runtime": 16.3952,
      "eval_samples_per_second": 29.216,
      "eval_steps_per_second": 7.319,
      "step": 810
    },
    {
      "epoch": 3.018557179308745,
      "grad_norm": 0.1762756109237671,
      "learning_rate": 8.323076923076924e-05,
      "loss": 0.0076,
      "step": 815
    },
    {
      "epoch": 3.0371143586174902,
      "grad_norm": 0.08358477801084518,
      "learning_rate": 8.246153846153847e-05,
      "loss": 0.0061,
      "step": 820
    },
    {
      "epoch": 3.0556715379262354,
      "grad_norm": 0.16279029846191406,
      "learning_rate": 8.16923076923077e-05,
      "loss": 0.0064,
      "step": 825
    },
    {
      "epoch": 3.0742287172349805,
      "grad_norm": 0.1373613029718399,
      "learning_rate": 8.092307692307693e-05,
      "loss": 0.007,
      "step": 830
    },
    {
      "epoch": 3.092785896543725,
      "grad_norm": 0.14423421025276184,
      "learning_rate": 8.015384615384616e-05,
      "loss": 0.0059,
      "step": 835
    },
    {
      "epoch": 3.1113430758524703,
      "grad_norm": 0.09968077391386032,
      "learning_rate": 7.938461538461539e-05,
      "loss": 0.0074,
      "step": 840
    },
    {
      "epoch": 3.1299002551612154,
      "grad_norm": 0.16248179972171783,
      "learning_rate": 7.861538461538462e-05,
      "loss": 0.0063,
      "step": 845
    },
    {
      "epoch": 3.1484574344699605,
      "grad_norm": 0.11797481030225754,
      "learning_rate": 7.784615384615385e-05,
      "loss": 0.004,
      "step": 850
    },
    {
      "epoch": 3.1670146137787056,
      "grad_norm": 0.14023922383785248,
      "learning_rate": 7.707692307692308e-05,
      "loss": 0.0063,
      "step": 855
    },
    {
      "epoch": 3.1855717930874508,
      "grad_norm": 0.11626896262168884,
      "learning_rate": 7.630769230769231e-05,
      "loss": 0.0062,
      "step": 860
    },
    {
      "epoch": 3.204128972396196,
      "grad_norm": 0.15069468319416046,
      "learning_rate": 7.553846153846155e-05,
      "loss": 0.006,
      "step": 865
    },
    {
      "epoch": 3.222686151704941,
      "grad_norm": 0.15554726123809814,
      "learning_rate": 7.476923076923077e-05,
      "loss": 0.0048,
      "step": 870
    },
    {
      "epoch": 3.241243331013686,
      "grad_norm": 0.15193897485733032,
      "learning_rate": 7.4e-05,
      "loss": 0.005,
      "step": 875
    },
    {
      "epoch": 3.259800510322431,
      "grad_norm": 0.18269093334674835,
      "learning_rate": 7.323076923076924e-05,
      "loss": 0.0068,
      "step": 880
    },
    {
      "epoch": 3.278357689631176,
      "grad_norm": 0.14482349157333374,
      "learning_rate": 7.246153846153847e-05,
      "loss": 0.0074,
      "step": 885
    },
    {
      "epoch": 3.296914868939921,
      "grad_norm": 0.18245826661586761,
      "learning_rate": 7.169230769230769e-05,
      "loss": 0.0083,
      "step": 890
    },
    {
      "epoch": 3.315472048248666,
      "grad_norm": 0.3243353068828583,
      "learning_rate": 7.092307692307693e-05,
      "loss": 0.005,
      "step": 895
    },
    {
      "epoch": 3.3340292275574113,
      "grad_norm": 0.11486106365919113,
      "learning_rate": 7.015384615384616e-05,
      "loss": 0.008,
      "step": 900
    },
    {
      "epoch": 3.3525864068661564,
      "grad_norm": 0.03797201067209244,
      "learning_rate": 6.938461538461539e-05,
      "loss": 0.0037,
      "step": 905
    },
    {
      "epoch": 3.3711435861749015,
      "grad_norm": 0.1504993438720703,
      "learning_rate": 6.861538461538462e-05,
      "loss": 0.0074,
      "step": 910
    },
    {
      "epoch": 3.3897007654836466,
      "grad_norm": 0.05550603196024895,
      "learning_rate": 6.784615384615385e-05,
      "loss": 0.0067,
      "step": 915
    },
    {
      "epoch": 3.4082579447923917,
      "grad_norm": 0.15007807314395905,
      "learning_rate": 6.707692307692308e-05,
      "loss": 0.0049,
      "step": 920
    },
    {
      "epoch": 3.426815124101137,
      "grad_norm": 0.1255291849374771,
      "learning_rate": 6.630769230769232e-05,
      "loss": 0.006,
      "step": 925
    },
    {
      "epoch": 3.4453723034098815,
      "grad_norm": 0.06816896796226501,
      "learning_rate": 6.553846153846154e-05,
      "loss": 0.0056,
      "step": 930
    },
    {
      "epoch": 3.4639294827186267,
      "grad_norm": 0.09785047918558121,
      "learning_rate": 6.476923076923077e-05,
      "loss": 0.0041,
      "step": 935
    },
    {
      "epoch": 3.482486662027372,
      "grad_norm": 0.19633111357688904,
      "learning_rate": 6.400000000000001e-05,
      "loss": 0.0069,
      "step": 940
    },
    {
      "epoch": 3.501043841336117,
      "grad_norm": 0.1508166790008545,
      "learning_rate": 6.323076923076924e-05,
      "loss": 0.0083,
      "step": 945
    },
    {
      "epoch": 3.519601020644862,
      "grad_norm": 0.27053165435791016,
      "learning_rate": 6.246153846153846e-05,
      "loss": 0.0072,
      "step": 950
    },
    {
      "epoch": 3.538158199953607,
      "grad_norm": 0.10593950003385544,
      "learning_rate": 6.16923076923077e-05,
      "loss": 0.0045,
      "step": 955
    },
    {
      "epoch": 3.5567153792623523,
      "grad_norm": 0.09616003930568695,
      "learning_rate": 6.092307692307693e-05,
      "loss": 0.0054,
      "step": 960
    },
    {
      "epoch": 3.575272558571097,
      "grad_norm": 0.13927967846393585,
      "learning_rate": 6.015384615384616e-05,
      "loss": 0.0072,
      "step": 965
    },
    {
      "epoch": 3.593829737879842,
      "grad_norm": 0.14001351594924927,
      "learning_rate": 5.938461538461538e-05,
      "loss": 0.0041,
      "step": 970
    },
    {
      "epoch": 3.612386917188587,
      "grad_norm": 0.2764330804347992,
      "learning_rate": 5.861538461538462e-05,
      "loss": 0.0101,
      "step": 975
    },
    {
      "epoch": 3.6309440964973323,
      "grad_norm": 0.1784777194261551,
      "learning_rate": 5.784615384615385e-05,
      "loss": 0.0088,
      "step": 980
    },
    {
      "epoch": 3.6495012758060774,
      "grad_norm": 0.13275086879730225,
      "learning_rate": 5.7076923076923086e-05,
      "loss": 0.005,
      "step": 985
    },
    {
      "epoch": 3.6680584551148225,
      "grad_norm": 0.15900005400180817,
      "learning_rate": 5.630769230769231e-05,
      "loss": 0.0064,
      "step": 990
    },
    {
      "epoch": 3.6866156344235677,
      "grad_norm": 0.1361328363418579,
      "learning_rate": 5.553846153846154e-05,
      "loss": 0.0046,
      "step": 995
    },
    {
      "epoch": 3.7051728137323128,
      "grad_norm": 0.20566657185554504,
      "learning_rate": 5.4769230769230775e-05,
      "loss": 0.0056,
      "step": 1000
    },
    {
      "epoch": 3.723729993041058,
      "grad_norm": 0.15206153690814972,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 0.0063,
      "step": 1005
    },
    {
      "epoch": 3.742287172349803,
      "grad_norm": 0.17625011503696442,
      "learning_rate": 5.323076923076923e-05,
      "loss": 0.0047,
      "step": 1010
    },
    {
      "epoch": 3.760844351658548,
      "grad_norm": 0.1648191511631012,
      "learning_rate": 5.2461538461538464e-05,
      "loss": 0.007,
      "step": 1015
    },
    {
      "epoch": 3.779401530967293,
      "grad_norm": 0.11322477459907532,
      "learning_rate": 5.1692307692307694e-05,
      "loss": 0.0026,
      "step": 1020
    },
    {
      "epoch": 3.797958710276038,
      "grad_norm": 0.07166347652673721,
      "learning_rate": 5.092307692307693e-05,
      "loss": 0.0053,
      "step": 1025
    },
    {
      "epoch": 3.816515889584783,
      "grad_norm": 0.10050664097070694,
      "learning_rate": 5.0153846153846154e-05,
      "loss": 0.0061,
      "step": 1030
    },
    {
      "epoch": 3.835073068893528,
      "grad_norm": 0.11535969376564026,
      "learning_rate": 4.9384615384615384e-05,
      "loss": 0.005,
      "step": 1035
    },
    {
      "epoch": 3.8536302482022733,
      "grad_norm": 0.11478409916162491,
      "learning_rate": 4.861538461538462e-05,
      "loss": 0.0059,
      "step": 1040
    },
    {
      "epoch": 3.8721874275110184,
      "grad_norm": 0.17218802869319916,
      "learning_rate": 4.784615384615384e-05,
      "loss": 0.0056,
      "step": 1045
    },
    {
      "epoch": 3.8907446068197635,
      "grad_norm": 0.22582155466079712,
      "learning_rate": 4.707692307692308e-05,
      "loss": 0.0053,
      "step": 1050
    },
    {
      "epoch": 3.909301786128508,
      "grad_norm": 0.1752561628818512,
      "learning_rate": 4.630769230769231e-05,
      "loss": 0.0062,
      "step": 1055
    },
    {
      "epoch": 3.9278589654372533,
      "grad_norm": 0.19329234957695007,
      "learning_rate": 4.553846153846154e-05,
      "loss": 0.0087,
      "step": 1060
    },
    {
      "epoch": 3.9464161447459984,
      "grad_norm": 0.13499748706817627,
      "learning_rate": 4.476923076923077e-05,
      "loss": 0.0044,
      "step": 1065
    },
    {
      "epoch": 3.9649733240547436,
      "grad_norm": 0.09557396173477173,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0033,
      "step": 1070
    },
    {
      "epoch": 3.9835305033634887,
      "grad_norm": 0.18166109919548035,
      "learning_rate": 4.323076923076923e-05,
      "loss": 0.0051,
      "step": 1075
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.14097389578819275,
      "learning_rate": 4.2461538461538465e-05,
      "loss": 0.0047,
      "step": 1080
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.014543057419359684,
      "eval_runtime": 16.3961,
      "eval_samples_per_second": 29.214,
      "eval_steps_per_second": 7.319,
      "step": 1080
    }
  ],
  "logging_steps": 5,
  "max_steps": 1350,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.73905309869015e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
